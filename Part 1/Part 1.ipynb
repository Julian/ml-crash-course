{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Machine Learning Crash Course: H2O AutoML\n",
        "\n",
        "This is a [Jupyter](https://jupyter.org/) Notebook. When you execute code within the notebook, the results appear beneath the code. To execute a code chunk, place your cursor on the cell and press *Shift+Enter*.\n",
        "\n",
        "### Start H2O\n",
        "\n",
        "Import the **h2o** Python module and `H2OAutoML` class and initialize a local H2O cluster."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "import h2o\n",
        "from h2o.automl import H2OAutoML\n",
        "h2o.init()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Data\n",
        "\n",
        "We're going to use a subset of a publically available [Product Backorders](https://www.kaggle.com/tiredgeek/predict-bo-trial/data) dataset.  The goal here is to predict whether or not a product will be put on backorder status, given a number of product metrics such as current inventory, transit time, demand forecasts and prior sales."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "# Use local data file or download from GitHub\n",
        "data_path = \"https://github.com/h2oai/h2o-tutorials/raw/master/h2o-world-2017/automl/data/product_backorders.csv\"\n",
        "\n",
        "# Load data into H2O\n",
        "df = h2o.import_file(data_path)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "We're going to be predicting one of the specific columns of our dataset. Specifically, one that indicates whether a given product was put on backorder or not. Let's inspect the dataset we've loaded, which was returned to us as a \"data frame\"."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We can also investigate the distributions and types of the columns we have."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "df.describe()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, let's identify the response & predictor columns by saving them as `x` and `y`.  The `\"sku\"` column is a unique identifier so we'll want to remove that from the set of our predictors."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "y = \"went_on_backorder\"\n",
        "x = df.columns\n",
        "x.remove(y)\n",
        "x.remove(\"sku\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build Our Model\n",
        "\n",
        "We're going to run H2O's AutoML, and ask it to build at most 10 models to try and predict our outcome."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "automl = H2OAutoML(max_models=5)\n",
        "automl.train(x=x, y=y, training_frame=df)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Leaderboard\n",
        "\n",
        "AutoML has built us multiple slightly different models in an attempt to predict the outcome we asked it to learn. Which model is the best, and how good is it?\n",
        "\n",
        "H2O ranks the models it has built for us in an *AutoML Leaderboard*, a ranked list of the models it has built, sorted by a *metric* that indicates how good each model is.\n",
        "\n",
        "The leader model is stored at `automl.leader` and the leaderboard is stored at `automl.leaderboard`."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "leaderboard = automl.leaderboard\n",
        "leader = automl.leader"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we will view a snapshot of the top models.  Here we should see the two Stacked Ensembles at or near the top of the leaderboard.  Stacked Ensembles can almost always outperform a single model."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "leaderboard.head()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "To view the entire leaderboard, specify the `rows` argument of the `head()` method as the total number of rows:"
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "leaderboard.head(rows=leaderboard.nrows)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Making Predictions\n",
        "\n",
        "Now that we have a model, we can ask the model for predictions on a new data point."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "automl.leader.predict(\n",
        "    h2o.H2OFrame(\n",
        "        [\n",
        "            [12345678, 13, 30, 20, 80, 100, 130, 50, 20, 100, 32, 0, False, 0, 100, 80, 100, False, False, False, False, False],\n",
        "[12345678234, 1223, 30, 20, 80, 1030, 130, 50, 20, 100, 321, 0, False, 0, 100, 80, 100, False, False, False, False, False],\n",
        "        ],\n",
        "        column_names=[\"sku\", \"national_inv\", \"lead_time\", \"in_transit_qty\", \"forecast_3_month\", \"forecast_6_month\", \"forecast_9_month\", \"sales_1_month\", \"sales_3_month\", \"sales_6_month\", \"sales_9_month\", \"min_bank\", \"potential_issue\", \"pieces_past_due\", \"perf_6_month_avg\", \"perf_12_month_avg\", \"local_bo_qty\", \"deck_risk\", \"oe_constraint\", \"ppap_risk\", \"stop_auto_buy\", \"rev_stop\"],\n",
        "    ),\n",
        ")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "collapsed": false,
        "outputHidden": false,
        "inputHidden": false
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Save Leader Model\n",
        "\n",
        "Once we have trained a model, and decided we want to keep it (or keep the leader model), we can save that model for reuse later."
      ],
      "metadata": {}
    },
    {
      "cell_type": "code",
      "source": [
        "h2o.save_model(automl.leader, path = \"./product_backorders_model_bin\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {}
    },
    {
      "cell_type": "markdown",
      "source": [
        "The contents of this notebook were lightly adapted from a tutorial in the [official H2O AutoML documentation](http://docs.h2o.ai/h2o-tutorials/latest-stable/h2o-world-2017/automl/index.html). There are many more interesting tutorials to work through there. Explore them!"
      ],
      "metadata": {}
    }
  ],
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "0.15.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}